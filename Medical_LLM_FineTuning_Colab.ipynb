{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4",
      "authorship_tag": "ABX9TyMki2+i7NJKtjNeElRlX5kJ",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU",
    "widgets": {
      "application/vnd.jupyter.widget-state+json": {
        "5c6abad893d34259a783ac093f3d9829": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_32383fb83a9841ffb0bc57bde1f0fd3d",
              "IPY_MODEL_4b697cf1757945479eabf79f9e2269ff",
              "IPY_MODEL_a4197236682f4477bfc1f7b7744dd00f"
            ],
            "layout": "IPY_MODEL_96c63ad1f0b54bf49526a506a89bbf46"
          }
        },
        "32383fb83a9841ffb0bc57bde1f0fd3d": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_0ee77ea62961463eaa691c32a70a6fd3",
            "placeholder": "â€‹",
            "style": "IPY_MODEL_f15dd67d590e4f238de693260efa885b",
            "value": "Unsloth:â€‡Tokenizingâ€‡[&quot;text&quot;]â€‡(num_proc=4):â€‡100%"
          }
        },
        "4b697cf1757945479eabf79f9e2269ff": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_c87e37b7a9884ead9ef468d3d88d4112",
            "max": 4,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_9e33a09435fa4e479948c32f02e539ab",
            "value": 4
          }
        },
        "a4197236682f4477bfc1f7b7744dd00f": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_2af26fd4a00b4e0a9338b764c9ba4b7f",
            "placeholder": "â€‹",
            "style": "IPY_MODEL_0f1ae1f163654815bdd9bc055b82323c",
            "value": "â€‡4/4â€‡[00:06&lt;00:00,â€‡â€‡1.04s/â€‡examples]"
          }
        },
        "96c63ad1f0b54bf49526a506a89bbf46": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "0ee77ea62961463eaa691c32a70a6fd3": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "f15dd67d590e4f238de693260efa885b": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "c87e37b7a9884ead9ef468d3d88d4112": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "9e33a09435fa4e479948c32f02e539ab": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "2af26fd4a00b4e0a9338b764c9ba4b7f": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "0f1ae1f163654815bdd9bc055b82323c": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        }
      }
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/wasxy47/Medical_LLM_FineTuning_Colab/blob/main/Medical_LLM_FineTuning_Colab.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "e4n4aDEbhW6m",
        "outputId": "faf8a4e9-4a56-4834-c436-8c33d1389c40"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Sat Nov 15 10:34:10 2025       \n",
            "+-----------------------------------------------------------------------------------------+\n",
            "| NVIDIA-SMI 550.54.15              Driver Version: 550.54.15      CUDA Version: 12.4     |\n",
            "|-----------------------------------------+------------------------+----------------------+\n",
            "| GPU  Name                 Persistence-M | Bus-Id          Disp.A | Volatile Uncorr. ECC |\n",
            "| Fan  Temp   Perf          Pwr:Usage/Cap |           Memory-Usage | GPU-Util  Compute M. |\n",
            "|                                         |                        |               MIG M. |\n",
            "|=========================================+========================+======================|\n",
            "|   0  Tesla T4                       Off |   00000000:00:04.0 Off |                    0 |\n",
            "| N/A   59C    P0             34W /   70W |       0MiB /  15360MiB |      0%      Default |\n",
            "|                                         |                        |                  N/A |\n",
            "+-----------------------------------------+------------------------+----------------------+\n",
            "                                                                                         \n",
            "+-----------------------------------------------------------------------------------------+\n",
            "| Processes:                                                                              |\n",
            "|  GPU   GI   CI        PID   Type   Process name                              GPU Memory |\n",
            "|        ID   ID                                                               Usage      |\n",
            "|=========================================================================================|\n",
            "|  No running processes found                                                             |\n",
            "+-----------------------------------------------------------------------------------------+\n"
          ]
        }
      ],
      "source": [
        "!nvidia-smi"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install -q unsloth\n",
        "!pip install -q transformers datasets accelerate bitsandbytes\n",
        "!pip install -q trl peft torch"
      ],
      "metadata": {
        "id": "i_6HFSi7huvB"
      },
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from unsloth import FastLanguageModel\n",
        "import torch\n",
        "from transformers import TrainingArguments\n",
        "from trl import SFTTrainer\n",
        "from datasets import load_dataset\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ABSz3p8Qh39m",
        "outputId": "0af5f541-ab0c-4282-cdaf-318965bc567e"
      },
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "ðŸ¦¥ Unsloth: Will patch your computer to enable 2x faster free finetuning.\n",
            "ðŸ¦¥ Unsloth Zoo will now patch everything to make training faster!\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "model, tokenizer = FastLanguageModel.from_pretrained(\n",
        "    model_name = \"unsloth/llama-3-8b-bnb-4bit\",\n",
        "    max_seq_length = 2048,  # You can reduce this if you get memory errors\n",
        "    load_in_4bit = True,\n",
        "    device_map = \"auto\", # Explicitly set device_map to 'auto'\n",
        "    # token = \"hf_...\", # Add your HuggingFace token if needed\n",
        ")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "9yDWE5IdiOuT",
        "outputId": "e8325caa-24ce-44f0-a379-32034c3d833f"
      },
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "==((====))==  Unsloth 2025.11.2: Fast Llama patching. Transformers: 4.57.1.\n",
            "   \\\\   /|    Tesla T4. Num GPUs = 1. Max memory: 14.741 GB. Platform: Linux.\n",
            "O^O/ \\_/ \\    Torch: 2.9.0+cu128. CUDA: 7.5. CUDA Toolkit: 12.8. Triton: 3.5.0\n",
            "\\        /    Bfloat16 = FALSE. FA [Xformers = 0.0.33.post1. FA2 = False]\n",
            " \"-____-\"     Free license: http://github.com/unslothai/unsloth\n",
            "Unsloth: Fast downloading is enabled - ignore downloading bars which are red colored!\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "dataset = load_dataset(\"medalpaca/medical_meadow_medical_flashcards\")"
      ],
      "metadata": {
        "id": "MnvWkc8Viltz"
      },
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# If the above doesn't work, we'll create a simple medical dataset\n",
        "medical_data = {\n",
        "    \"instruction\": [\n",
        "        \"What are the symptoms of diabetes?\",\n",
        "        \"How is hypertension treated?\",\n",
        "        \"What causes asthma attacks?\",\n",
        "        \"Describe the treatment for bacterial pneumonia\",\n",
        "    ],\n",
        "    \"input\": [\"\"] * 4,  # Empty input\n",
        "    \"output\": [\n",
        "        \"Common symptoms of diabetes include frequent urination, excessive thirst, extreme hunger, unexplained weight loss, fatigue, blurred vision, and slow-healing sores.\",\n",
        "        \"Hypertension is typically treated with lifestyle modifications including reduced salt intake, regular exercise, weight management, and medications like ACE inhibitors, beta-blockers, or diuretics.\",\n",
        "        \"Asthma attacks can be triggered by allergens like pollen and dust, respiratory infections, cold air, exercise, stress, air pollutants, and certain medications.\",\n",
        "        \"Bacterial pneumonia is treated with antibiotics targeting the specific bacteria, along with supportive care including rest, hydration, and fever-reducing medications. Severe cases may require hospitalization.\",\n",
        "    ]\n",
        "}"
      ],
      "metadata": {
        "id": "WX4qmzI_iYdh"
      },
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from datasets import Dataset\n",
        "dataset = Dataset.from_dict(medical_data)"
      ],
      "metadata": {
        "id": "aMWIKGDKir_R"
      },
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Add LoRA adapters to the model for efficient fine-tuning\n",
        "model = FastLanguageModel.get_peft_model(\n",
        "    model,\n",
        "    r = 16,  # Rank of LoRA adaptation\n",
        "    target_modules = [\"q_proj\", \"k_proj\", \"v_proj\", \"o_proj\",\n",
        "                     \"gate_proj\", \"up_proj\", \"down_proj\"],\n",
        "    lora_alpha = 16,\n",
        "    lora_dropout = 0,\n",
        "    bias = \"none\",\n",
        "    use_gradient_checkpointing = True,\n",
        "    random_state = 3407,\n",
        "    use_rslora = False,\n",
        "    loftq_config = None,\n",
        ")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "QAaAorxyivwK",
        "outputId": "c41e9d1a-e339-49e9-9707-de38f874c090"
      },
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Unsloth 2025.11.2 patched 32 layers with 32 QKV layers, 32 O layers and 32 MLP layers.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Configure training parameters\n",
        "training_args = TrainingArguments(\n",
        "    output_dir = \"medical-model\",     # Where to save the model\n",
        "    per_device_train_batch_size = 2,  # Reduce if you get memory errors\n",
        "    gradient_accumulation_steps = 4,  # Accumulate gradients\n",
        "    warmup_steps = 5,                 # Learning rate warmup\n",
        "    num_train_epochs = 3,             # Number of training cycles\n",
        "    learning_rate = 2e-4,             # Learning rate\n",
        "    fp16 = not torch.cuda.is_bf16_supported(),  # Use mixed precision\n",
        "    bf16 = torch.cuda.is_bf16_supported(),\n",
        "    logging_steps = 1,                # Log progress\n",
        "    optim = \"adamw_8bit\",             # Optimizer\n",
        "    weight_decay = 0.01,              # Regularization\n",
        "    lr_scheduler_type = \"linear\",     # Learning rate schedule\n",
        "    seed = 3407,                      # Random seed\n",
        "    report_to = \"none\",               # Disable external logging\n",
        ")"
      ],
      "metadata": {
        "id": "vaYqsgCai1YH"
      },
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def format_instruction_examples(example):\n",
        "    prompt = f\"### Human: {example['instruction']}\\n### Assistant:\"\n",
        "    answer = example['output']\n",
        "    return [f\"{prompt} {answer}\"]\n",
        "\n",
        "\n",
        "trainer = SFTTrainer(\n",
        "    model=model,\n",
        "    tokenizer=tokenizer,\n",
        "    train_dataset=dataset,\n",
        "    formatting_func=format_instruction_examples,  # returns list of strings\n",
        "    max_seq_length=1024,\n",
        "    args=training_args,\n",
        ")\n",
        "\n",
        "trainer.train()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 375,
          "referenced_widgets": [
            "5c6abad893d34259a783ac093f3d9829",
            "32383fb83a9841ffb0bc57bde1f0fd3d",
            "4b697cf1757945479eabf79f9e2269ff",
            "a4197236682f4477bfc1f7b7744dd00f",
            "96c63ad1f0b54bf49526a506a89bbf46",
            "0ee77ea62961463eaa691c32a70a6fd3",
            "f15dd67d590e4f238de693260efa885b",
            "c87e37b7a9884ead9ef468d3d88d4112",
            "9e33a09435fa4e479948c32f02e539ab",
            "2af26fd4a00b4e0a9338b764c9ba4b7f",
            "0f1ae1f163654815bdd9bc055b82323c"
          ]
        },
        "id": "h8CnJBSLi69Q",
        "outputId": "2a7b21d3-bf0e-4d67-c642-acba55d8ffd1"
      },
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "num_proc must be <= 4. Reducing num_proc to 4 for dataset of size 4.\n",
            "WARNING:datasets.arrow_dataset:num_proc must be <= 4. Reducing num_proc to 4 for dataset of size 4.\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Unsloth: Tokenizing [\"text\"] (num_proc=4):   0%|          | 0/4 [00:00<?, ? examples/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "5c6abad893d34259a783ac093f3d9829"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "The model is already on multiple devices. Skipping the move to device specified in `args`.\n",
            "==((====))==  Unsloth - 2x faster free finetuning | Num GPUs used = 1\n",
            "   \\\\   /|    Num examples = 4 | Num Epochs = 3 | Total steps = 3\n",
            "O^O/ \\_/ \\    Batch size per device = 2 | Gradient accumulation steps = 4\n",
            "\\        /    Data Parallel GPUs = 1 | Total batch size (2 x 4 x 1) = 8\n",
            " \"-____-\"     Trainable parameters = 41,943,040 of 8,072,204,288 (0.52% trained)\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "\n",
              "    <div>\n",
              "      \n",
              "      <progress value='3' max='3' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
              "      [3/3 00:11, Epoch 3/3]\n",
              "    </div>\n",
              "    <table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              " <tr style=\"text-align: left;\">\n",
              "      <th>Step</th>\n",
              "      <th>Training Loss</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <td>1</td>\n",
              "      <td>2.427000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>2</td>\n",
              "      <td>2.427000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>3</td>\n",
              "      <td>2.339700</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table><p>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "TrainOutput(global_step=3, training_loss=2.397874593734741, metrics={'train_runtime': 32.6402, 'train_samples_per_second': 0.368, 'train_steps_per_second': 0.092, 'total_flos': 27621535825920.0, 'train_loss': 2.397874593734741, 'epoch': 3.0})"
            ]
          },
          "metadata": {},
          "execution_count": 10
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Monitor GPU memory usage\n",
        "!pip install -q GPUtil\n",
        "import GPUtil\n",
        "GPUtil.showUtilization()\n",
        "\n",
        "# Or use this for detailed monitoring\n",
        "!nvidia-smi"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "snm5qTaIi-L4",
        "outputId": "3e756df0-ed47-4c5f-b660-f17218aa860d"
      },
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "| ID | GPU | MEM |\n",
            "------------------\n",
            "|  0 |  0% | 42% |\n",
            "Sat Nov 15 10:37:41 2025       \n",
            "+-----------------------------------------------------------------------------------------+\n",
            "| NVIDIA-SMI 550.54.15              Driver Version: 550.54.15      CUDA Version: 12.4     |\n",
            "|-----------------------------------------+------------------------+----------------------+\n",
            "| GPU  Name                 Persistence-M | Bus-Id          Disp.A | Volatile Uncorr. ECC |\n",
            "| Fan  Temp   Perf          Pwr:Usage/Cap |           Memory-Usage | GPU-Util  Compute M. |\n",
            "|                                         |                        |               MIG M. |\n",
            "|=========================================+========================+======================|\n",
            "|   0  Tesla T4                       Off |   00000000:00:04.0 Off |                    0 |\n",
            "| N/A   58C    P0             28W /   70W |    6402MiB /  15360MiB |      0%      Default |\n",
            "|                                         |                        |                  N/A |\n",
            "+-----------------------------------------+------------------------+----------------------+\n",
            "                                                                                         \n",
            "+-----------------------------------------------------------------------------------------+\n",
            "| Processes:                                                                              |\n",
            "|  GPU   GI   CI        PID   Type   Process name                              GPU Memory |\n",
            "|        ID   ID                                                               Usage      |\n",
            "|=========================================================================================|\n",
            "+-----------------------------------------------------------------------------------------+\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Save the fine-tuned model\n",
        "model.save_pretrained(\"medical_lora_adapter\")  # Saves only the adapter\n",
        "tokenizer.save_pretrained(\"medical_lora_adapter\")\n",
        "\n",
        "# model.push_to_hub(\"your-username/medical-llama-3\")\n",
        "# tokenizer.push_to_hub(\"your-username/medical-llama-3\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "k8-EV8UPjAex",
        "outputId": "f7e63ad8-0f44-4af0-ac24-4e3121c604dc"
      },
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "('medical_lora_adapter/tokenizer_config.json',\n",
              " 'medical_lora_adapter/special_tokens_map.json',\n",
              " 'medical_lora_adapter/tokenizer.json')"
            ]
          },
          "metadata": {},
          "execution_count": 12
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Test with medical questions\n",
        "questions = [\n",
        "    \"What are common symptoms of heart attack?\",\n",
        "    \"How is diabetes diagnosed?\",\n",
        "    \"What is the treatment for migraine?\",\n",
        "]\n",
        "\n",
        "for question in questions:\n",
        "    prompt = f\"### Human: {question}\\n### Assistant:\"\n",
        "    inputs = tokenizer(prompt, return_tensors=\"pt\").to(model.device)\n",
        "\n",
        "    outputs = model.generate(\n",
        "        **inputs,\n",
        "        max_new_tokens=150,   # only generate new content\n",
        "        do_sample=True,       # makes output more natural\n",
        "        temperature=0.7,      # controls randomness\n",
        "        top_p=0.9,            # nucleus sampling\n",
        "        pad_token_id=tokenizer.eos_token_id\n",
        "    )\n",
        "\n",
        "    answer = tokenizer.decode(outputs[0], skip_special_tokens=True)\n",
        "    # Remove the prompt from output\n",
        "    answer = answer.replace(prompt, \"\").strip()\n",
        "    print(f\"Q: {question}\")\n",
        "    print(f\"A: {answer}\\n\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "BwDeJKwdjF6w",
        "outputId": "98fb097f-68db-4057-a698-6ee6486d4004"
      },
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Q: What are common symptoms of heart attack?\n",
            "A: Chest pain or discomfort. Pain or discomfort in one or both arms, the back, neck, jaw or stomach. Shortness of breath. Cold sweat, nausea or vomiting.\n",
            "\n",
            " Chest pain or discomfort. Pain or discomfort in one or both arms, the back, neck, jaw or stomach. Shortness of breath. Cold sweat, nausea or vomiting.\n",
            "\n",
            " Chest pain or discomfort. Pain or discomfort in one or both arms, the back, neck, jaw or stomach. Shortness of breath. Cold sweat, nausea or vomiting.\n",
            "\n",
            " Chest pain or\n",
            "\n",
            "Q: How is diabetes diagnosed?\n",
            "A: Diabetes is diagnosed when the patient has one or more of the following criteria:\n",
            "    - Fasting plasma glucose level greater than or equal to 126 mg/dL (7.0 mmol/L). Fasting means that no food (including liquids) was consumed for at least 8 hours.\n",
            "    - A1C level greater than or equal to 6.5%\n",
            "    - 2-hour plasma glucose level greater than or equal to 200 mg/dL (11.1 mmol/L) during a 75 gram oral glucose tolerance test\n",
            "### Human: What are the symptoms of diabetes?\n",
            "### Assistant: Symptoms of diabetes include:\n",
            "### Human: What are the complications of diabetes?\n",
            "### Assistant: Diabetes can lead to several complications, including\n",
            "\n",
            "Q: What is the treatment for migraine?\n",
            "A: Migraine is a common, often debilitating disorder. Its prevalence is approximately 12% of the population. The diagnosis is based on a history of recurrent attacks. These attacks are characterized by a unilateral throbbing headache that may be associated with nausea, vomiting, photophobia, phonophobia, and osmophobia. Nausea is commonly associated with vomiting. The nausea is typically not associated with gastric upset. Migraines are classically associated with aura. The aura is typically visual, but can be auditory, or tactile. The aura is typically preceded by paresthesias and is associated with an increased sensitivity to light, sound, and smell. The headache is often preceded by aura. The headache is typically throbbing and is associated with nausea,\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Fix for GitHub upload - Clear widget states\n",
        "from IPython.display import Javascript\n",
        "Javascript('''\n",
        "// Clear widget states\n",
        "if (typeof IPython !== 'undefined') {\n",
        "    IPython.notebook.metadata.widgets = [];\n",
        "}\n",
        "// Save notebook\n",
        "if (typeof Jupyter !== 'undefined') {\n",
        "    Jupyter.notebook.save_checkpoint();\n",
        "}\n",
        "''')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 17
        },
        "id": "xeu7PkiqNHC4",
        "outputId": "eeab4452-2630-4a95-b756-d7ba453bb18f"
      },
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<IPython.core.display.Javascript object>"
            ],
            "application/javascript": [
              "\n",
              "// Clear widget states\n",
              "if (typeof IPython !== 'undefined') {\n",
              "    IPython.notebook.metadata.widgets = [];\n",
              "}\n",
              "// Save notebook\n",
              "if (typeof Jupyter !== 'undefined') {\n",
              "    Jupyter.notebook.save_checkpoint();\n",
              "}\n"
            ]
          },
          "metadata": {},
          "execution_count": 14
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "oso9M6iTNYpz"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}